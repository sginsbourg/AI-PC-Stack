#!/usr/bin/env python3

import subprocess
import time
import os
from pathlib import Path
import asyncio
import aiohttp
import json

class AIPoweredLeadFinder:
    def __init__(self):
        self.base_url = "http://localhost:8000"
    
    async def check_services(self):
        """Check if all AI services are running"""
        services = {
            "Ollama": "http://localhost:11434",
            "Open Manus": "http://localhost:8000",
            "Elasticsearch": "http://localhost:9200"
        }
        
        print("ğŸ” Checking services...")
        async with aiohttp.ClientSession() as session:
            for service, url in services.items():
                try:
                    async with session.get(f"{url}/" if service != "Ollama" else f"{url}/api/tags") as response:
                        if response.status in [200, 401]:
                            print(f"âœ… {service} is running")
                        else:
                            print(f"âŒ {service} returned status {response.status}")
                except Exception as e:
                    print(f"âŒ {service} is not accessible: {e}")
    
    async def run_enhanced_pipeline(self):
        """Run the complete AI-enhanced pipeline"""
        
        print("ğŸš€ Starting AI-Powered Lead Finder with Open Manus AI...")
        print("âœ… Confirmed: All AI models running locally - No API keys needed!")
        
        # Check services
        await self.check_services()
        
        # Step 1: Initialize AI models
        print("\nğŸ¤– Step 1: Initializing AI models...")
        try:
            subprocess.run(["./scripts/init_models.sh"], check=True)
            print("âœ… AI models initialized!")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Model initialization failed: {e}")
            return
        
        # Step 2: Run Nutch crawl
        print("\nğŸ“¡ Step 2: Starting web crawl with Apache Nutch...")
        try:
            subprocess.run(["./scripts/crawl.sh"], check=True)
            print("âœ… Crawl completed successfully!")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Crawl failed: {e}")
            return
        
        # Wait for indexing
        print("â³ Waiting for data indexing...")
        time.sleep(30)
        
        # Step 3: Run AI-enhanced lead analysis
        print("\nğŸ” Step 3: Analyzing leads with AI...")
        try:
            # Import and run the enhanced analyzer
            from lead_analyzer.analyzer import EnhancedLeadAnalyzer
            analyzer = EnhancedLeadAnalyzer()
            leads = await analyzer.generate_leads_report()
            print("âœ… AI analysis completed!")
            
            # Display results
            self.display_ai_results(leads)
            
        except Exception as e:
            print(f"âŒ AI analysis failed: {e}")
            return
    
    def display_ai_results(self, leads):
        """Display AI-enhanced results"""
        print(f"\nğŸ¯ AI Analysis Complete!")
        print(f"ğŸ“Š Found {len(leads)} qualified leads")
        
        if leads:
            top_leads = sorted(leads, key=lambda x: x['relevance_score'], reverse=True)[:5]
            
            print("\nğŸ† Top 5 AI-Analyzed Leads:")
            print("="*100)
            
            for i, lead in enumerate(top_leads, 1):
                print(f"\n{i}. {lead.get('company', 'Unknown')}")
                print(f"   ğŸ“ URL: {lead['url']}")
                print(f"   â­ Relevance Score: {lead['relevance_score']}/10")
                print(f"   ğŸ¯ Intent: {lead['intent_classification']}")
                print(f"   ğŸ’° Value: {lead['potential_value']}")
                print(f"   ğŸ”§ Tech Stack: {', '.join(lead['technology_stack'][:3])}")
                print(f"   ğŸ“§ Emails: {', '.join(lead['emails'][:2])}")
                
                if lead.get('personalized_approach'):
                    print(f"   ğŸ’¡ Approach: {lead['personalized_approach'][:100]}...")
                
                print("-" * 100)
        
        print(f"\nğŸ“ Results saved in:")
        print("   - results/ai_leads.csv (CSV format)")
        print("   - results/ai_leads_detailed.json (Detailed JSON)")
        print("   - results/summary_report.md (Summary report)")

async def main():
    finder = AIPoweredLeadFinder()
    await finder.run_enhanced_pipeline()

if __name__ == "__main__":
    # Create necessary directories
    Path("results").mkdir(exist_ok=True)
    Path("scripts").mkdir(exist_ok=True)
    Path("models").mkdir(exist_ok=True)
    
    # Make scripts executable
    for script in Path("scripts").glob("*.sh"):
        script.chmod(0o755)
    
    asyncio.run(main())